#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : 1_åˆ†è¯
# @Time         : 2023/5/21 17:14
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  :
import os

import pandas as pd
import streamlit
from annotated_text import annotated_text, annotation
from sentence_transformers import SentenceTransformer

from meutils.pipe import *
from meutils.serving.st_utils import *

title = Path(__file__).stem.split('_')[-1]
st.set_page_config(title, page_icon='ğŸ”¥', layout='wide', initial_sidebar_state='collapsed')
st.title(title)

hide_st_style('ğŸ”¥DevelopedBy@æ•°æ®ç§‘å­¦ç ”å‘ä¸­å¿ƒ-AIå›¢é˜Ÿ')

SentenceTransformer = lru_cache(SentenceTransformer)


def nlp(text_pair, model='shibing624/text2vec-base-chinese'):
    cache_folder = None
    if Path('/data/MODEL/huggingface').is_dir():
        cache_folder = '/data/MODEL/huggingface'
    embeddings = (
        SentenceTransformer(model, cache_folder=cache_folder)
        .encode(text_pair, normalize_embeddings=True)
    )
    _ = [{'æ–‡æœ¬1': text_pair[0], 'æ–‡æœ¬2': text_pair[1], 'ç›¸ä¼¼åº¦': (embeddings[0] * embeddings[1]).sum()}]
    return pd.DataFrame(_)


nlp = disk_cache(nlp, 'cachedir_sim')

with st.form(title):
    text1 = """
    ã€Šä¸œåŒ—è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¿¡æ¯æŠ€æœ¯ç®¡ç†åˆ¶åº¦ã€‹ç¬¬å…­æ¡ å…¬å¸ç»ç†å±‚è´Ÿè´£è½å®ä¿¡æ¯æŠ€æœ¯ç®¡ç†ç›®æ ‡ï¼Œå¯¹ä¿¡æ¯æŠ€æœ¯ç®¡ç†å·¥ä½œæ‰¿æ‹…è´£ä»»ï¼Œå±¥è¡Œä¸‹åˆ—èŒè´£ï¼š
ï¼ˆä¸€ï¼‰ç»„ç»‡å®æ–½è‘£äº‹ä¼šç›¸å…³å†³è®®ï¼›
ï¼ˆäºŒï¼‰å»ºç«‹è´£ä»»æ˜ç¡®ã€ç¨‹åºæ¸…æ™°çš„ä¿¡æ¯æŠ€æœ¯ç®¡ç†ç»„ç»‡æ¶æ„ï¼Œæ˜ç¡®ç®¡ç†èŒè´£ã€å·¥ä½œç¨‹åºå’Œåè°ƒæœºåˆ¶ï¼›
ï¼ˆä¸‰ï¼‰å®Œå–„ç»©æ•ˆè€ƒæ ¸å’Œè´£ä»»è¿½ç©¶æœºåˆ¶ï¼›
ï¼ˆå››ï¼‰å…¬å¸ç« ç¨‹è§„å®šæˆ–è‘£äº‹ä¼šæˆæƒçš„å…¶ä»–ä¿¡æ¯æŠ€æœ¯ç®¡ç†èŒè´£ã€‚
    """
    text2 = """
    ç¬¬å…«æ¡ è¯åˆ¸åŸºé‡‘ç»è¥æœºæ„ç»è¥ç®¡ç†å±‚è´Ÿè´£è½å®ä¿¡æ¯æŠ€æœ¯ç®¡ç†ç›®æ ‡ï¼Œå¯¹ä¿¡æ¯æŠ€æœ¯ç®¡ç†å·¥ä½œæ‰¿æ‹…è´£ä»»ï¼Œå±¥è¡Œä¸‹åˆ—èŒè´£ï¼š    
    """

    cols = st.columns(3)
    with cols[0]:
        option = st.selectbox('ç®—æ³•ï¼š', ('shibing624/text2vec-base-chinese', 'GanymedeNil/text2vec-large-chinese'))

    text1 = st.text_area("æ–‡æœ¬1ï¼š", text1.strip(), height=120)
    text2 = st.text_area("æ–‡æœ¬2ï¼š", text2.strip(), height=120)

    if st.form_submit_button('ğŸš€å¼€å§‹è®¡ç®—'):
        with st.spinner('AIæ­£åœ¨è®¡ç®—...'):
            st.dataframe(nlp([text1, text2], option))
